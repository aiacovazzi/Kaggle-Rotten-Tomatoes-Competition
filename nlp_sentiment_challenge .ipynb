{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEb7-fngb_QF"
      },
      "source": [
        "## NLP Kaggle Challenge by Antonio Raffaele Iacovazzi - Mat: 756263 "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading libraries and data"
      ],
      "metadata": {
        "id": "odWrExVEyQFo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAvUGUnZcAb-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "723155da-9aaa-42d8-ce56-5750970033eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spacytextblob\n",
            "  Downloading spacytextblob-4.0.0-py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: textblob<0.16.0,>=0.15.3 in /usr/local/lib/python3.7/dist-packages (from spacytextblob) (0.15.3)\n",
            "Requirement already satisfied: spacy<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from spacytextblob) (3.3.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (21.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (2.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (57.4.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (8.0.17)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (4.64.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (3.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (4.1.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (0.9.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (1.21.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (2.4.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (0.6.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (3.3.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (0.7.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (3.0.9)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (1.0.7)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (0.4.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (2.0.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (1.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<4.0,>=3.0->spacytextblob) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<4.0,>=3.0->spacytextblob) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<4.0,>=3.0->spacytextblob) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=3.0->spacytextblob) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=3.0->spacytextblob) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=3.0->spacytextblob) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=3.0->spacytextblob) (1.24.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob<0.16.0,>=0.15.3->spacytextblob) (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob<0.16.0,>=0.15.3->spacytextblob) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob<0.16.0,>=0.15.3->spacytextblob) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob<0.16.0,>=0.15.3->spacytextblob) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<4.0,>=3.0->spacytextblob) (2.0.1)\n",
            "Installing collected packages: spacytextblob\n",
            "Successfully installed spacytextblob-4.0.0\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.3.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.3.0) (3.3.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.1.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.21.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.11.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.10)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 7.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 7.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 51.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 48.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 42.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 237 kB 49.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 92 kB 11.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 49.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 48.3 MB 87 kB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 829 kB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 6.9 MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#importing libraries\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import seaborn as sns #data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from copy import copy\n",
        "import spacy\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import one_hot\n",
        "\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import GRU\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import Dropout\n",
        "\n",
        "!pip install spacytextblob\n",
        "!python -m textblob.download_corpora\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "# A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q -U \"tensorflow-text==2.8.*\"\n",
        "!pip install -q tf-models-official==2.7.0\n",
        "import os\n",
        "import shutil\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BKdgPxWacP9q",
        "outputId": "51e24869-eadd-4df1-a048-6f6bb9efd8de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PhraseId  SentenceId                                             Phrase  \\\n",
              "0         1           1  A series of escapades demonstrating the adage ...   \n",
              "1         2           1  A series of escapades demonstrating the adage ...   \n",
              "2         3           1                                           A series   \n",
              "3         4           1                                                  A   \n",
              "4         5           1                                             series   \n",
              "\n",
              "   Sentiment  \n",
              "0          1  \n",
              "1          2  \n",
              "2          2  \n",
              "3          2  \n",
              "4          2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c69bd97e-b8d6-4b5e-b0b9-4a3a82b6d3a6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c69bd97e-b8d6-4b5e-b0b9-4a3a82b6d3a6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c69bd97e-b8d6-4b5e-b0b9-4a3a82b6d3a6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c69bd97e-b8d6-4b5e-b0b9-4a3a82b6d3a6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#loading data\n",
        "train = pd.read_table('/content/drive/MyDrive/NLP Sentiment Challenge/train.tsv')\n",
        "test = pd.read_table('/content/drive/MyDrive/NLP Sentiment Challenge/test.tsv')\n",
        "#check dataset\n",
        "train.head()\n",
        "#test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "YnPgl8eGyTMX",
        "outputId": "e0548666-c139-46a3-a514-9a5aa19904cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f543c3d4790>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Visualization of data set\n",
        "a = train.Sentiment.value_counts()\n",
        "a = pd.DataFrame(a)\n",
        "a['Rating'] = a.index\n",
        "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "sns.barplot(y='Sentiment', x='Rating', data=a)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The majority of sentences are in the neutral class. <br>\n",
        "This probably because every review is splitted in sub-sentences and most of them are neutral.<br>\n",
        "The dataset is really unbalanced, so it will be difficult to train on it properly."
      ],
      "metadata": {
        "id": "7b9odIGn5Hmt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBWFf7c5dKoT"
      },
      "source": [
        "# First attempt: a simple ML approach (useful for a baseline).<br>\n",
        "Kaggle score: 0.61680"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neeIgBcEajWR"
      },
      "source": [
        "## Preprocessing steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAjOhcJTeMrj"
      },
      "source": [
        "**Some consideration about stopwords removing in the movie review domain**:<br>\n",
        "I think that the usual stopwords list doesn't fit in this kind of task, this because in sentiment analysis is necessary to catch some change of polarity in a sentence.<br>For example \"not good\" must be recognized as representative of the negative class.<br>In order to do this I will modify the stopwords set removing all the negation.<br>Furthermore I will add some recurrent words like \"movie\" and \"film\" that can't have a sentiment semantic in this domain because are the object of the discourse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "j3_pFl-OdoWz",
        "outputId": "c05b89b4-fb9c-4504-f1da-1df63fad6493"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             frequency\n",
              "the              51633\n",
              "of               32702\n",
              "and              32177\n",
              "to               22761\n",
              "in               13997\n",
              "...                ...\n",
              "girls              157\n",
              "genuine            157\n",
              "target             157\n",
              "examination        157\n",
              "thoroughly         157\n",
              "\n",
              "[777 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e02b1601-8703-47f5-93aa-38b0ea3d4a7b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>the</th>\n",
              "      <td>51633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>of</th>\n",
              "      <td>32702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>and</th>\n",
              "      <td>32177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>22761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>in</th>\n",
              "      <td>13997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>girls</th>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>genuine</th>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>examination</th>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>thoroughly</th>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>777 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e02b1601-8703-47f5-93aa-38b0ea3d4a7b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e02b1601-8703-47f5-93aa-38b0ea3d4a7b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e02b1601-8703-47f5-93aa-38b0ea3d4a7b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#check if \"movie\" and \"film\" can be considered stopwords\n",
        "\n",
        "word_vectorizer = CountVectorizer(ngram_range=(1,1), analyzer='word', min_df=0.001)\n",
        "sparse_matrix = word_vectorizer.fit_transform(train['Phrase'])\n",
        "frequencies = sum(sparse_matrix).toarray()[0]\n",
        "freq = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names_out (), columns=['frequency'])\n",
        "freq.sort_values('frequency', ascending=False)\n",
        "\n",
        "#\"film\" has a frequency of 6733 and \"movie\" has a frequency of 6241, then i can consider this words stopwords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Saqa5SBOqI3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85303835-2270-47c7-e2d4-80d9e7013dce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'd', 'did', 'do', 'does', 'doing', 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'more', 'most', 'my', 'myself', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', 'she', \"she's\", 'should', \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'we', 'were', 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves', 'movie', 'movies', 'film', 'films']\n"
          ]
        }
      ],
      "source": [
        "#creating a customized stopwords set\n",
        "stop_words = stopwords.words('english') \n",
        "#print(stop_words)\n",
        "r = re.compile(\"\\w*n'\\w*\")\n",
        "negation = list(filter(r.match, stop_words)) # Read Note below\n",
        "#print(negation)\n",
        "stop_words = set(stop_words)-set(negation)\n",
        "stop_words=sorted(stop_words)\n",
        "r = re.compile(\"\\w*n$\")\n",
        "negation = list(filter(r.match, stop_words)) # Read Note below\n",
        "#print(negation)\n",
        "#select only real negation in the brief form\n",
        "negation = [ 'ain', 'aren', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'mightn', 'mustn', 'needn', 'shouldn', 'wasn', 'weren',  'won', 'wouldn','no', 'nor', 'not']\n",
        "stop_words = set(stop_words)-set(negation)\n",
        "stop_words=sorted(stop_words)\n",
        "#add \"movie\" and \"film\" in the list\n",
        "stop_words.append('movie')\n",
        "stop_words.append('movies')\n",
        "stop_words.append('film')\n",
        "stop_words.append('films')\n",
        "print(stop_words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPxfxmBl2K0t"
      },
      "source": [
        "**Defining the preprocessing pipeline**<br>\n",
        "In order to work with less and more simple senteces, the following steps will be performed:<br>\n",
        "\n",
        "*   Lowercase transformation\n",
        "*   Numbers removing\n",
        "*   Tokenization + symbol removing\n",
        "*   Stopword removing\n",
        "*   Stemming or Lemmatization\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSQk6Ojl5VA3"
      },
      "outputs": [],
      "source": [
        "lrb_rrb = ['lrb','rrb']\n",
        "def preprocessDataset(text, split, stopword, normalization): \n",
        "    \n",
        "    #remove single quotes \n",
        "    text = text.replace(\"'\", \"\")    \n",
        "    \n",
        "    text = text.lower()\n",
        "\n",
        "    numberremove_text = ''.join(c for c in text if not c.isdigit())\n",
        "\n",
        "    #word tokenization using text-to-word-sequence\n",
        "    tokenized_train_set = text_to_word_sequence(numberremove_text,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',split=\" \")   \n",
        "\n",
        "    #removing the special string lrb and rrb (brackets)\n",
        "    tokenized_train_set = [i for i in tokenized_train_set if not i in lrb_rrb]\n",
        "\n",
        "    #stop word removal\n",
        "    if stopword == True:\n",
        "      stopwordremoved_set = [i for i in tokenized_train_set if not i in stop_words]\n",
        "    else:\n",
        "      stopwordremoved_set = tokenized_train_set\n",
        "        \n",
        "    #Stemming\n",
        "    if(normalization=='stem'):      \n",
        "      norm_token_train_set = [stemmer.stem(word) for word in stopwordremoved_set]\n",
        "\n",
        "    if(normalization=='lemma'):  \n",
        "      #lemmatize each word to its lemma      \n",
        "      norm_token_train_set = [lemmatizer.lemmatize(i) for i in stopwordremoved_set]\n",
        "\n",
        "    if(normalization=='none'):  \n",
        "      norm_token_train_set = stopwordremoved_set\n",
        "     \n",
        "    #join words into sentence\n",
        "    if split == False:\n",
        "      stopwordremove_text = ' '.join(norm_token_train_set)\n",
        "    else:\n",
        "      stopwordremove_text = norm_token_train_set #if we want the vector representation\n",
        "\n",
        "    return stopwordremove_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8txg55_3uvP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "751e1262-5087-4288-d26d-f019b7861011"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    seri escapad demonstr adag good goos also good...\n",
              "1                 seri escapad demonstr adag good goos\n",
              "2                                                 seri\n",
              "3                                                     \n",
              "4                                                 seri\n",
              "Name: Phrase, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "processed_train = copy(train)\n",
        "processed_train['Phrase'] = processed_train['Phrase'].apply(preprocessDataset, split=False, stopword = True, normalization= 'stem')\n",
        "phrase = processed_train['Phrase']\n",
        "sentiment = processed_train['Sentiment']\n",
        "phrase.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S791fseRmLv1"
      },
      "outputs": [],
      "source": [
        "list_data = list(zip(phrase, sentiment))\n",
        "train_set = pd.DataFrame(list_data,columns = ['Phrase', 'Sentiment'])\n",
        "#remove empty rows \n",
        "train_set['Phrase'].replace('', np.nan, inplace=True)\n",
        "train_set.dropna(subset = [\"Phrase\"], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d54pyJBlarOl"
      },
      "source": [
        "## Training & Tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAEdlcDLCJDc"
      },
      "source": [
        "The data are ready to be represented in a more suitable way for algorithms, here will use a bag of words model that is a simple matrix document X term where in each cell is represented the frequency of that word for that document.<br>\n",
        "Instead of consider only single words also bigram (couple of word) will be taken into accout, this in order to catch the occurrence of negation or other two-words combination that can have a meaning per sé."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcPTiaOlupVc"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "N_GRAM_MIN = 1 #the lower bound for n-gram representation\n",
        "N_GRAM_MAX = 2 #the upper bound for n-gram representation\n",
        "NUM_OF_SPLITS = 3\n",
        "\n",
        "#create bag of words vector\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "bow = CountVectorizer(ngram_range=(N_GRAM_MIN, N_GRAM_MAX),\n",
        "min_df = 1) #bigrams\n",
        "#Construct the required TF matrix by fitting and transforming the data\n",
        "bow_matrix = bow.fit_transform(train_set['Phrase'])\n",
        "\n",
        "#df = pd.DataFrame(data=bow_matrix.toarray(),columns = bow.get_feature_names()) #can crash with a lot of feature, better avoid to execute this\n",
        "#df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e0JDpTEDG2l"
      },
      "source": [
        "Now the BoW representation will feed three classical machine learning algorithm that are:\n",
        "\n",
        "*   Linear Support Vector Machine\n",
        "*   Decision Tree\n",
        "*   Logistic Regression\n",
        "*   Naive Bayes\n",
        "\n",
        "In order to evaluate their performance a 3-fold cross validation is performed.<br>\n",
        "By means of this technique is possible to stress the algorithm with different combination of train and validation set obtaining so more meningful result about accuracy.<br>\n",
        "The 3-fold is used to speed up the search for good hyperparaters, once done this a final evluation with the 10-fold will be done.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysqZHyubjvVp"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "models = []\n",
        "models.append(('Support Vector Machine',LinearSVC(max_iter=9000)))\n",
        "models.append(('Decision Tree',DecisionTreeClassifier()))\n",
        "models.append(('Logistic Regression',LogisticRegression(max_iter=9000)))\n",
        "models.append(('Bayes',MultinomialNB()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TceSPizDDxK2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77dbbe0e-66bd-44ed-df93-f8f24fc4c4e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine: 0.637928 (0.001071)\n",
            "Decision Tree: 0.622404 (0.000902)\n",
            "Logistic Regression: 0.652863 (0.000727)\n",
            "Bayes: 0.604885 (0.002361)\n"
          ]
        }
      ],
      "source": [
        "# compare models with 10-fold cross-validation\n",
        "kf = model_selection.StratifiedKFold(n_splits=NUM_OF_SPLITS,shuffle=True, random_state = 1)\n",
        "\n",
        "for name, model in models:\n",
        "    cv_scores = model_selection.cross_val_score(model, bow_matrix, train_set['Sentiment'], cv=kf)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_scores.mean(), cv_scores.std())\n",
        "    print(msg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrbNsKo3a8Xk"
      },
      "source": [
        "## Evaluating Results\n",
        "Results are presented in the following way:<br>\n",
        "name_of_algorithm: average_accuracy(standard_deviation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puZjxDV6EOsN"
      },
      "source": [
        "**Results with:** <br>\n",
        "*N_GRAM_MIN = 1*<br>\n",
        "*N_GRAM_MAX = 1*<br>\n",
        "\n",
        "---\n",
        "Support Vector Machine: 0.618291 (0.001244)<br>\n",
        "Decision Tree: 0.622339 (0.001535)<br>\n",
        "Logistic Regression: 0.631030 (0.002014)<br>\n",
        "Bayes: 0.602637 (0.000442)<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8iyEK7eOKrP"
      },
      "source": [
        "**Results with:** <br>\n",
        "*N_GRAM_MIN = 1*<br>\n",
        "*N_GRAM_MAX = 2*<br>\n",
        "\n",
        "---\n",
        "Support Vector Machine: 0.640506 (0.001193)<br>\n",
        "Decision Tree: 0.623136 (0.001891)<br>\n",
        "Logistic Regression: 0.653983 (0.001412)<br>\n",
        "Bayes: 0.612974 (0.002300)<br>\n",
        "The results are increased a lot, this probably because the presence of 2-grams allows to better distinguish between classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR4r3F9IRGCU"
      },
      "source": [
        "**Results with:** <br>\n",
        "*N_GRAM_MIN = 2*<br>\n",
        "*N_GRAM_MAX = 2*<br>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Support Vector Machine: 0.623848 (0.000649)<br>\n",
        "Decision Tree: 0.616905 (0.000745)<br>\n",
        "Logistic Regression: 0.619282 (0.001219)<br>\n",
        "Bayes: 0.598855 (0.001755)<br>\n",
        "Here only bigrams are taken into account, the results are lower than before and also compared to the experiment with only unigrams, probably bigrams are not sufficiently expressive alone to well separate the various class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW5UobS2XAjg"
      },
      "source": [
        "**Results with:** <br>\n",
        "*N_GRAM_MIN = 2*<br>\n",
        "*N_GRAM_MAX = 3*<br>\n",
        "\n",
        "---\n",
        "Support Vector Machine: 0.624029 (0.000518)<br>\n",
        "Decision Tree: 0.617048 (0.000733)<br>\n",
        "Logistic Regression: 0.616963 (0.001334)<br>\n",
        "Bayes: 0.590014 (0.002135)<br>\n",
        "Here we have bigrams and trigrams, the results is slightly lower than the previous in front of an increased complexity of the model.<br>\n",
        "This shows that my initial assumption about n-grams with n>1 was good but only combining unigram and bigram.<br>\n",
        "I will work with the unigram+bigram in this ML context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkfOwyuubEGl"
      },
      "source": [
        "This result suggest us that the Logistic Regression classifier is the best choice among the three classifier.<br>\n",
        "An accuracy of 0.65 on the validation set is pretty high considering the kind of task. Let's see how it behave on the actual test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYKZVdEOjAEp",
        "outputId": "6effefc1-b415-4382-de35-f841e316abc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(66292, 72825)\n"
          ]
        }
      ],
      "source": [
        "final_model = LogisticRegression(max_iter=9000)\n",
        "final_model.fit(bow_matrix, train_set['Sentiment'])\n",
        "\n",
        "processed_test = test\n",
        "\n",
        "processed_test['Phrase'] = processed_test['Phrase'].apply(preprocessDataset, split=False, stopword = True, normalization= 'stem')\n",
        "\n",
        "test_id = processed_test['PhraseId']\n",
        "test_text = processed_test['Phrase']\n",
        "bow_matrix_test = bow.transform(processed_test['Phrase'])\n",
        "\n",
        "print(bow_matrix_test.shape)\n",
        "\n",
        "y_prdict = final_model.predict(bow_matrix_test)\n",
        "\n",
        "submission = pd.DataFrame(list(zip(test_id, y_prdict)),\n",
        "               columns =['PhraseId', 'Sentiment'])\n",
        "submission.head(20)\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/NLP Sentiment Challenge/submission_logistic.csv', index=False)\n",
        "#renamed submission_test\n",
        "#kaggle score: 0.61680"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "End up with an accuracy of 0.61680 that is really good considering the simple model and the complexity of the task."
      ],
      "metadata": {
        "id": "fDmrE5vGx7vX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V86T14XTDsJt"
      },
      "source": [
        "# Second Attempt: an heuristic way based on senti-wordnet + ML technique.\n",
        "Kaggle score 0.54193<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another way to approach this kind of tasks is using a lexicon made up with the purpose of represent the sentiment content of each word in english.<br>\n"
      ],
      "metadata": {
        "id": "1dVm7aLvzW0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What I want to do?\n"
      ],
      "metadata": {
        "id": "dU7FlhF7TvL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*Training phase:*\n",
        "\n",
        "1.   For each review create a set of negated words and the set of normal words (where the polarity is directly taken from sentiwordnet).\n",
        "2.   Compute the sentiment score of the two sets, invert the score of the negated set.\n",
        "3.   Compute the overall sentiment of the sentence summing all the scores (negative and positive), then obtain a final score as a single value by the *formula tot_pos_score - tot_neg_score* or as a triplet [pos_value, neg_value, obj_value]. \n",
        "\n",
        "4. Try to derive a rule using the results of the previous algorithm, if it is bad the train a ML model in order to try to map every score to a class [0,4].\n",
        "\n",
        "*Test phase:*\n",
        "1.   Compute the sentiment score of the sentence (steps 1-2-3 of the training phase).\n",
        "2. Try to predict the right class passing in input the score to the ML model."
      ],
      "metadata": {
        "id": "0mnAOlsUT1dX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the algorithm"
      ],
      "metadata": {
        "id": "S7jKhVn2g34L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YrtiUzEqe5A",
        "outputId": "6878c2fa-40f7-49c2-c456-df4109e13f50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import sentiwordnet as swn\n",
        "from nltk.corpus import wordnet as wn\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('omw-1.4')\n",
        "#Here I dont remove negation from stopwords, I will deal with negation using the algoritm previous described, then once made the two sets, all the common stopword will be removed.\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.Defaults.stop_words |= {\"movie\",\"film\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETdU-EVtL-A-"
      },
      "outputs": [],
      "source": [
        "#this simple program converts the POS of spacy into the one accepted by nltk-sentiwordnet\n",
        "def spacy_to_wn(tag):\n",
        "    if tag=='ADJ':\n",
        "        return wn.ADJ\n",
        "    elif tag == 'NOUN':\n",
        "        return wn.NOUN\n",
        "    elif tag=='ADV':\n",
        "        return wn.ADV\n",
        "    elif tag == 'VERB':\n",
        "        return wn.VERB\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rp-glO8hWrbr"
      },
      "outputs": [],
      "source": [
        "def get_sentiment(word,tag,mod):\n",
        "    \"\"\" returns list of pos neg and objective score. But returns empty list if not present in senti wordnet. \"\"\"\n",
        "\n",
        "    wn_tag = spacy_to_wn(tag)\n",
        "    if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV,  wn.VERB):\n",
        "        return [0,0,0]\n",
        "\n",
        "    synsets = wn.synsets(word, pos=wn_tag)\n",
        "    if not synsets:\n",
        "        return [0,0,0]\n",
        "\n",
        "    # Take the first sense, the most common\n",
        "    synset = synsets[0]\n",
        "    swn_synset = swn.senti_synset(synset.name())\n",
        "\n",
        "    if mod == 'normal':\n",
        "      return [swn_synset.pos_score(), swn_synset.neg_score(), swn_synset.obj_score()]\n",
        "    \n",
        "    if mod == 'negated':\n",
        "      return [swn_synset.neg_score(), swn_synset.pos_score(), swn_synset.obj_score()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-0MYxuElCjX"
      },
      "outputs": [],
      "source": [
        "def get_sentiment_array(text, neg_factor, debug):\n",
        "\n",
        "  doc = nlp(text)\n",
        "\n",
        "  negation_tokens = [tok for tok in doc if tok.dep_ == 'neg']\n",
        "\n",
        "  punctation_tokens = [tok for tok in doc if tok.dep_ == 'punct']\n",
        "\n",
        "  normal = []\n",
        "  negated = []\n",
        "\n",
        "  neg = False\n",
        "\n",
        "  for tok in doc:\n",
        "    if neg == False:\n",
        "      if tok in negation_tokens:\n",
        "        neg = True\n",
        "        normal.append([tok.lemma_.lower(),'ADV']) #lemmatized version of the token, for senti_wordnet \"not\" is an adverb, so I force this conversion. I take into account negation in the normal context because have a strong polarity in sw.\n",
        "      else:\n",
        "        if not(tok in punctation_tokens): #in this case word goes to normal bucket but discard punctuation\n",
        "          if not(tok.is_stop):\n",
        "            normal.append([tok.lemma_.lower(),tok.pos_]) #lemmatized version of the token\n",
        "    else:\n",
        "      if tok in punctation_tokens:\n",
        "        neg = False\n",
        "      else:      \n",
        "        if not(tok in negation_tokens): #in negation context new negation are discarded (still in negative polarity)\n",
        "          if not(tok.is_stop):\n",
        "            negated.append([tok.lemma_.lower(),tok.pos_]) #lemmatized version of the token\n",
        "\n",
        "  if debug==True:\n",
        "    scores = [get_sentiment(x,y,'normal') for (x,y) in normal]\n",
        "\n",
        "    nr = list(zip(normal,scores))\n",
        "\n",
        "    neg_scores = [get_sentiment(x,y,'negated') for (x,y) in negated]\n",
        "\n",
        "    neg = list(zip(negated,neg_scores))\n",
        "\n",
        "    print (nr)\n",
        "\n",
        "    print (neg)\n",
        "\n",
        "  senti_val_nor = [get_sentiment(x,y,'normal') for (x,y) in normal]\n",
        "  senti_val_neg = [get_sentiment(x,y,'normal') for (x,y) in negated]\n",
        "\n",
        "  return senti_val_nor+senti_val_neg\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment_score (array):\n",
        "  pos = sum( x[0] for x in array)\n",
        "  neg = sum( x[1] for x in array)\n",
        "  return pos-neg"
      ],
      "metadata": {
        "id": "55MVuPiT1GdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment_triplet (array):\n",
        "  pos = sum( x[0] for x in array)\n",
        "  neg = sum( x[1] for x in array)\n",
        "  obj = sum( x[2] for x in array)\n",
        "  return [pos,neg,obj]\n",
        "   "
      ],
      "metadata": {
        "id": "_qqKi6ucHhXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applyng the algorithm on a smaller training set\n",
        "In order to catch the behaviour of the algorithm i will work on a small training set made of full reviews only, this in order to use less time since the previous algorithm is quite slow on the full training set."
      ],
      "metadata": {
        "id": "mulXzTwJhBiq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRqzQLvLPABa"
      },
      "outputs": [],
      "source": [
        "sentence_id = train.groupby(['SentenceId'])['PhraseId'].min()\n",
        "sentence_id = [x - 1 for x in sentence_id]\n",
        "train_or =  train.iloc[sentence_id] #train only (full) reviews\n",
        "\n",
        "scores = train_or['Phrase'].apply(get_sentiment_array, neg_factor=1, debug=False).apply(get_sentiment_score)\n",
        "\n",
        "sentiment = train_or['Sentiment']\n",
        "phrase = train_or['Phrase']\n",
        "\n",
        "list_data = list(zip(phrase,scores, sentiment))\n",
        "train_set_or = pd.DataFrame(list_data,columns = ['Phrase','Score', 'Sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_or"
      ],
      "metadata": {
        "id": "XgmRqcv843Xl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "0d64f932-77c5-467f-d611-ec20321e3d9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Phrase  Score  Sentiment\n",
              "0     A series of escapades demonstrating the adage ...  2.625          1\n",
              "1     This quiet , introspective and entertaining in...  0.250          4\n",
              "2     Even fans of Ismail Merchant 's work , I suspe... -1.000          1\n",
              "3     A positively thrilling combination of ethnogra... -2.125          3\n",
              "4     Aggressive self-glorification and a manipulati...  1.000          1\n",
              "...                                                 ...    ...        ...\n",
              "8524  ... either you 're willing to go with this cla... -0.250          2\n",
              "8525  Despite these annoyances , the capable Claybur...  0.375          2\n",
              "8526  -LRB- Tries -RRB- to parody a genre that 's al...  0.375          1\n",
              "8527  The movie 's downfall is to substitute plot fo... -0.875          1\n",
              "8528  The film is darkly atmospheric , with Herrmann... -0.375          2\n",
              "\n",
              "[8529 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04a49650-9b83-40d7-bf04-6381f84df10c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Score</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2.625</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This quiet , introspective and entertaining in...</td>\n",
              "      <td>0.250</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A positively thrilling combination of ethnogra...</td>\n",
              "      <td>-2.125</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Aggressive self-glorification and a manipulati...</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8524</th>\n",
              "      <td>... either you 're willing to go with this cla...</td>\n",
              "      <td>-0.250</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8525</th>\n",
              "      <td>Despite these annoyances , the capable Claybur...</td>\n",
              "      <td>0.375</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8526</th>\n",
              "      <td>-LRB- Tries -RRB- to parody a genre that 's al...</td>\n",
              "      <td>0.375</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8527</th>\n",
              "      <td>The movie 's downfall is to substitute plot fo...</td>\n",
              "      <td>-0.875</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8528</th>\n",
              "      <td>The film is darkly atmospheric , with Herrmann...</td>\n",
              "      <td>-0.375</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8529 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04a49650-9b83-40d7-bf04-6381f84df10c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-04a49650-9b83-40d7-bf04-6381f84df10c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-04a49650-9b83-40d7-bf04-6381f84df10c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some analysis on the results + simple classification algorithm<br>\n",
        "I excpect that for the positive review the score is positive and for the negative one is negative. <br> I also excpect some errors tha could bring noise in the training phase."
      ],
      "metadata": {
        "id": "Bwtr9Z1AYAFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get all the set separated by class\n",
        "s0 = train_set_or.query(\"`Sentiment` == 0\")\n",
        "s1 = train_set_or.query(\"`Sentiment` == 1\")\n",
        "s2 = train_set_or.query(\"`Sentiment` == 2\")\n",
        "s3 = train_set_or.query(\"`Sentiment` == 3\")\n",
        "s4 = train_set_or.query(\"`Sentiment` == 4\")\n",
        "#The mean will represent the tipycal score assumed by every class\n",
        "ms0 = s0[\"Score\"].mean()\n",
        "ms1 = s1[\"Score\"].mean()\n",
        "ms2 = s2[\"Score\"].mean()\n",
        "ms3 = s3[\"Score\"].mean()\n",
        "ms4 = s4[\"Score\"].mean()\n",
        "\n",
        "print(ms0)\n",
        "print(ms1)\n",
        "print(ms2)\n",
        "print(ms3)\n",
        "print(ms4)"
      ],
      "metadata": {
        "id": "BPFvvOJqYtGk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88058a57-8171-4a63-8ee2-dfd798f1e74d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.26898507462686566\n",
            "-0.08341318181818183\n",
            "-0.0032283987915407864\n",
            "0.22833003015941403\n",
            "0.47886651053864177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ms0 = -0.26898507462686566<br>\n",
        "ms1 = -0.08341318181818183<br>\n",
        "ms2 = -0.0032283987915407864<br>\n",
        "ms3 = 0.22833003015941403<br>\n",
        "ms4 = 0.47886651053864177<br>"
      ],
      "metadata": {
        "id": "CgxSzr_WDFin"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This means values are quite promising, here clearly see how every class a distinct mean value that represent the overall polarity of the sentences.<br>\n",
        "A first, naive, approach to exploit this information can be define some tresholds that define the class given a score."
      ],
      "metadata": {
        "id": "barzEMVTjEQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global t0\n",
        "global t1\n",
        "global t2\n",
        "global t3\n",
        "t0 =  (ms0+ms1)/2\n",
        "t1 =  (ms1+ms2)/2\n",
        "t2 =  (ms2+ms3)/2\n",
        "t3 =  (ms3+ms4)/2\n",
        "print(t0)\n",
        "print(t1)\n",
        "print(t2)\n",
        "print(t3)"
      ],
      "metadata": {
        "id": "K9ZbgV0c_vxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc6e5fb9-63a7-4bbc-c4e5-89c551f0bf1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.17619912822252376\n",
            "-0.04332079030486131\n",
            "0.11255081568393661\n",
            "0.3535982703490279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "t0 = -0.17619912822252376<br>\n",
        "t1 = -0.04332079030486131<br>\n",
        "t2 = 0.11255081568393661<br>\n",
        "t3 = 0.3535982703490279<br>"
      ],
      "metadata": {
        "id": "ptfKPiboDTZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These tresholds will be used to determine the class by the following way:<br>\n"
      ],
      "metadata": {
        "id": "8-7a71JiEbZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![treshold.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "hoTYeub5E1a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def determine_class(score):\n",
        "  if score < t0:\n",
        "    return 0\n",
        "  elif score >= t0 and score <= t1:\n",
        "    return 1\n",
        "  elif score >= t1 and score <= t2:\n",
        "    return 2\n",
        "  elif score >= t2 and score <= t3:\n",
        "    return 3\n",
        "  elif score > t3:\n",
        "    return 4"
      ],
      "metadata": {
        "id": "OoUzjSNSE9yR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "derived_sentiment = train_set_or['Score'].apply(determine_class)\n",
        "list_data = list(zip(phrase,scores, sentiment,derived_sentiment))\n",
        "train_set_or = pd.DataFrame(list_data,columns = ['Phrase','Score', 'Sentiment','Derived_Sentiment'])\n",
        "train_set_or"
      ],
      "metadata": {
        "id": "RotDf2uKFozQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "b57e1257-579c-4cbc-88ea-f2e5e170a971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Phrase  Score  Sentiment  \\\n",
              "0     A series of escapades demonstrating the adage ...  2.625          1   \n",
              "1     This quiet , introspective and entertaining in...  0.250          4   \n",
              "2     Even fans of Ismail Merchant 's work , I suspe... -1.000          1   \n",
              "3     A positively thrilling combination of ethnogra... -2.125          3   \n",
              "4     Aggressive self-glorification and a manipulati...  1.000          1   \n",
              "...                                                 ...    ...        ...   \n",
              "8524  ... either you 're willing to go with this cla... -0.250          2   \n",
              "8525  Despite these annoyances , the capable Claybur...  0.375          2   \n",
              "8526  -LRB- Tries -RRB- to parody a genre that 's al...  0.375          1   \n",
              "8527  The movie 's downfall is to substitute plot fo... -0.875          1   \n",
              "8528  The film is darkly atmospheric , with Herrmann... -0.375          2   \n",
              "\n",
              "      Derived_Sentiment  \n",
              "0                     4  \n",
              "1                     3  \n",
              "2                     0  \n",
              "3                     0  \n",
              "4                     4  \n",
              "...                 ...  \n",
              "8524                  0  \n",
              "8525                  4  \n",
              "8526                  4  \n",
              "8527                  0  \n",
              "8528                  0  \n",
              "\n",
              "[8529 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c484e85e-d111-49b7-a3be-f28ca5ad98ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Score</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Derived_Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2.625</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This quiet , introspective and entertaining in...</td>\n",
              "      <td>0.250</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A positively thrilling combination of ethnogra...</td>\n",
              "      <td>-2.125</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Aggressive self-glorification and a manipulati...</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8524</th>\n",
              "      <td>... either you 're willing to go with this cla...</td>\n",
              "      <td>-0.250</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8525</th>\n",
              "      <td>Despite these annoyances , the capable Claybur...</td>\n",
              "      <td>0.375</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8526</th>\n",
              "      <td>-LRB- Tries -RRB- to parody a genre that 's al...</td>\n",
              "      <td>0.375</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8527</th>\n",
              "      <td>The movie 's downfall is to substitute plot fo...</td>\n",
              "      <td>-0.875</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8528</th>\n",
              "      <td>The film is darkly atmospheric , with Herrmann...</td>\n",
              "      <td>-0.375</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8529 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c484e85e-d111-49b7-a3be-f28ca5ad98ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c484e85e-d111-49b7-a3be-f28ca5ad98ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c484e85e-d111-49b7-a3be-f28ca5ad98ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how good is this model for each class computing precision and recall:"
      ],
      "metadata": {
        "id": "cUTSKO4jJHsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Number of record for every derived class\n",
        "ds0 = train_set_or.query(\"`Derived_Sentiment` == 0\")\n",
        "ds1 = train_set_or.query(\"`Derived_Sentiment` == 1\")\n",
        "ds2 = train_set_or.query(\"`Derived_Sentiment` == 2\")\n",
        "ds3 = train_set_or.query(\"`Derived_Sentiment` == 3\")\n",
        "ds4 = train_set_or.query(\"`Derived_Sentiment` == 4\")\n",
        "\n",
        "num_d0_class = ds0.shape[0]\n",
        "num_d1_class = ds1.shape[0]\n",
        "num_d2_class = ds2.shape[0]\n",
        "num_d3_class = ds3.shape[0]\n",
        "num_d4_class = ds4.shape[0]\n",
        "\n",
        "#Number of record for every actual class\n",
        "num_0_class = s0.shape[0]\n",
        "num_1_class = s1.shape[0]\n",
        "num_2_class = s2.shape[0]\n",
        "num_3_class = s3.shape[0]\n",
        "num_4_class = s4.shape[0]\n",
        "\n",
        "#precision and recall for 0 class\n",
        "rel_retr_0 = (train_set_or.query(\"`Derived_Sentiment` == 0 and `Sentiment` == 0\").shape[0]) #intersecion between the relevant and the retrieved\n",
        "p0 = rel_retr_0/num_d0_class #precision = itersection/retrieved document\n",
        "r0 = rel_retr_0/num_0_class #recall = itersection/relevant document\n",
        "\n",
        "print('Precision for the class 0: '+str(p0))\n",
        "print('Recall for the class 0: '+str(r0))\n",
        "print('')\n",
        "#precision and recall for 1 class\n",
        "rel_retr_1 = (train_set_or.query(\"`Derived_Sentiment` == 1 and `Sentiment` == 1\").shape[0]) #intersecion between the relevant and the retrieved\n",
        "p1 = rel_retr_1/num_d1_class #precision = itersection/retrieved document\n",
        "r1 = rel_retr_1/num_1_class #recall = itersection/relevant document\n",
        "\n",
        "print('Precision for the class 1: '+str(p1))\n",
        "print('Recall for the class 1: '+str(r1))\n",
        "print('')\n",
        "\n",
        "#precision and recall for 2 class\n",
        "rel_retr_2 = (train_set_or.query(\"`Derived_Sentiment` == 2 and `Sentiment` == 2\").shape[0]) #intersecion between the relevant and the retrieved\n",
        "p2 = rel_retr_2/num_d2_class #precision = itersection/retrieved document\n",
        "r2 = rel_retr_2/num_2_class #recall = itersection/relevant document\n",
        "\n",
        "print('Precision for the class 2: '+str(p2))\n",
        "print('Recall for the class 2: '+str(r2))\n",
        "print('')\n",
        "\n",
        "#precision and recall for 3 class\n",
        "rel_retr_3 = (train_set_or.query(\"`Derived_Sentiment` == 3 and `Sentiment` == 3\").shape[0]) #intersecion between the relevant and the retrieved\n",
        "p3 = rel_retr_3/num_d3_class #precision = itersection/retrieved document\n",
        "r3 = rel_retr_3/num_3_class #recall = itersection/relevant document\n",
        "\n",
        "print('Precision for the class 3: '+str(p3))\n",
        "print('Recall for the class 3: '+str(r3))\n",
        "print('')\n",
        "\n",
        "#precision and recall for 4 class\n",
        "rel_retr_4 = (train_set_or.query(\"`Derived_Sentiment` == 4 and `Sentiment` == 4\").shape[0]) #intersecion between the relevant and the retrieved\n",
        "p4 = rel_retr_4/num_d4_class #precision = itersection/retrieved document\n",
        "r4 = rel_retr_4/num_4_class #recall = itersection/relevant document\n",
        "\n",
        "print('Precision for the class 4: '+str(p4))\n",
        "print('Recall for the class 4: '+str(r4))\n",
        "print('')\n",
        "\n",
        "accuracy = (rel_retr_0 + rel_retr_1 + rel_retr_2 +rel_retr_3 + rel_retr_4)/train_set_or.shape[0]\n",
        "print('Overall accuracy of the algorithm '+str(accuracy))\n",
        "print('')"
      ],
      "metadata": {
        "id": "TbmF6-LKJE_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b181ac-aca1-47ac-da3e-6172bbed41a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision for the class 0: 0.20204153467089053\n",
            "Recall for the class 0: 0.5354477611940298\n",
            "\n",
            "Precision for the class 1: 0.2964426877470356\n",
            "Recall for the class 1: 0.06818181818181818\n",
            "\n",
            "Precision for the class 2: 0.2897998093422307\n",
            "Recall for the class 2: 0.18368580060422962\n",
            "\n",
            "Precision for the class 3: 0.2718360071301248\n",
            "Recall for the class 3: 0.13140887548470487\n",
            "\n",
            "Precision for the class 4: 0.2497509133178346\n",
            "Recall for the class 4: 0.5870413739266198\n",
            "\n",
            "Overall accuracy of the algorithm 0.24446007738304606\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision for the class 0: 0.20204153467089053<br>\n",
        "Recall for the class 0: 0.5354477611940298<br>\n",
        "<br>\n",
        "Precision for the class 1: 0.2964426877470356<br>\n",
        "Recall for the class 1: 0.06818181818181818<br>\n",
        "<br>\n",
        "Precision for the class 2: 0.2897998093422307<br>\n",
        "Recall for the class 2: 0.18368580060422962<br>\n",
        "<br>\n",
        "Precision for the class 3: 0.2718360071301248<br>\n",
        "Recall for the class 3: 0.13140887548470487<br>\n",
        "<br>\n",
        "Precision for the class 4: 0.2497509133178346<br>\n",
        "Recall for the class 4: 0.5870413739266198<br>\n",
        "<br>\n",
        "Overall accuracy of the algorithm 0.24446007738304606"
      ],
      "metadata": {
        "id": "yn1W4riKDbeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is clear that this algorithm is really bad.<br>\n",
        "There is a higher recall on the two extreme class, but for the inner ones it cannot classify the sentences properly.<br>\n",
        "Probably a better choose of the tresholds can increase performace, but I think that the score measure is really instable and cannot provide a valid ground for derive a rule to make proper classification.<br>\n"
      ],
      "metadata": {
        "id": "2HxeD8_pQbbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#example for which a different treshold cannot make any difference:\n",
        "\n",
        "#negative class 0 and 1 shouldn't have positive scores\n",
        "eds0 = train_set_or.query(\"`Sentiment` == 0 and `Score` >= 0\").shape[0]\n",
        "eds1 = train_set_or.query(\"`Sentiment` == 1 and `Score` >= 0\").shape[0]\n",
        "\n",
        "#positive class 3 and 4 shouldn't have negative scores\n",
        "eds3 = train_set_or.query(\"`Sentiment` == 3 and `Score` <= 0\").shape[0]\n",
        "eds4 = train_set_or.query(\"`Sentiment` == 4 and `Score` <= 0\").shape[0]\n",
        "print('Completely wrong scores for 0: '+str(eds0) +  ' over '+str(num_0_class))\n",
        "print('Completely wrong scores for 1: '+str(eds1) +  ' over '+str(num_1_class))\n",
        "print('Completely wrong scores for 3: '+str(eds3) +  ' over '+str(num_3_class))\n",
        "print('Completely wrong scores for 4: '+str(eds4) +  ' over '+str(num_4_class))\n",
        "\n",
        "print('')"
      ],
      "metadata": {
        "id": "oHdOhYN1s8hG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dad2967-f034-4b17-b9e6-5d915d613fa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completely wrong scores for 0: 437 over 1072\n",
            "Completely wrong scores for 1: 1117 over 2200\n",
            "Completely wrong scores for 3: 966 over 2321\n",
            "Completely wrong scores for 4: 351 over 1281\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This because this algorithm rely on the assumption that the spacy pos tagger is always correct, and the SentiWordnet scores always reflect a proper sentiment for the word.<br>\n",
        "Furthermore this algorithm has a naive management of negation and can't deal whit inversion of polarity bring by word such as \"but\", \"however\" and so on. This is certainly a possible enhancement.<br>\n",
        "Finally there too many reviews that use words in a counterintuitive way using game of words, way of saying and so on, often a good review can use words that are negative in SentiWordnet and viceversa.\n",
        "Some example of misclasification:"
      ],
      "metadata": {
        "id": "by6lFZ5xyJPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Class 4 example:')\n",
        "t = \"Majidi 's direction has never been smoother or more confident .\"\n",
        "print(get_sentiment_score(get_sentiment_array(t, 1, True)))\n",
        "print('Here the negation is used in a wat that reinforce the polarity. This trick is ignored.')\n",
        "print('')\n",
        "\n",
        "t = \"A moving and not infrequently breathtaking film.\"\n",
        "print(get_sentiment_score(get_sentiment_array(t, 1, True)))\n",
        "print('The word breathtaking has any polarity, probably because is parsed as a verb by spacy.')\n",
        "print('')\n",
        "\n",
        "t = \"Well-acted , well-directed and , for all its moodiness , not too pretentious \"\n",
        "print(get_sentiment_score(get_sentiment_array(t, 1, True)))\n",
        "print('The word well is considered a stopword and the removed, the word pretentious has a negative score in the negated context, this because is probably considered a positive word by sentiwordnet.')\n",
        "print('')\n",
        "\n",
        "t = \"The film boasts dry humor and jarring shocks , plus moments of breathtaking mystery .\"\n",
        "print(get_sentiment_score(get_sentiment_array(t, 1, True)))\n",
        "print('Words like dry and shocks are considered negative, so this influence the overall polarity of the sentence.')\n",
        "print('')\n",
        "\n",
        "print('Class 0 example:')\n",
        "t = \"is that it 's a crime movie made by someone who obviously knows nothing about crime.\"\n",
        "print(get_sentiment_score(get_sentiment_array(t, 1, True)))\n",
        "print('Obviously is considered a positive word, the complex semantic of the sentence is not manageble by the sentiwordnet algorithm.')\n",
        "print('')\n",
        "\n",
        "t = \"My precious new Star Wars movie is a lumbering , wheezy drag ...\"\n",
        "print(get_sentiment_score(get_sentiment_array(t, 1, True)))\n",
        "print('Only the words precious and new gets a score. A positive one. This influence the overall polarity.')\n",
        "print('')\n",
        "\n",
        "t = \"Philosophically , intellectually and logistically a mess .\"\n",
        "print(get_sentiment_score(get_sentiment_array(t, 1, True)))\n",
        "print('Philosophically and intellectually gets a positive score. The word mess has not a sufficient negative score to influence the overall sentiment of the sentence.')\n",
        "print('')"
      ],
      "metadata": {
        "id": "L86iv5sZyIkc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dac75d0-4af5-4fea-9a9e-41d9dbf92b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 4 example:\n",
            "[(['majidi', 'PROPN'], [0, 0, 0]), (['direction', 'NOUN'], [0.0, 0.0, 1.0]), (['never', 'ADV'], [0.0, 0.625, 0.375])]\n",
            "[(['smooth', 'ADJ'], [0.0, 0.25, 0.75]), (['confident', 'ADJ'], [0.0, 0.375, 0.625])]\n",
            "0.0\n",
            "Here the negation is used in a wat that reinforce the polarity. This trick is ignored.\n",
            "\n",
            "[(['move', 'VERB'], [0.0, 0.0, 1.0]), (['not', 'ADV'], [0.0, 0.625, 0.375])]\n",
            "[(['infrequently', 'ADV'], [0.0, 0.0, 1.0]), (['breathtake', 'VERB'], [0, 0, 0])]\n",
            "-0.625\n",
            "The word breathtaking has any polarity, probably because is parsed as a verb by spacy.\n",
            "\n",
            "[(['act', 'VERB'], [0.0, 0.0, 1.0]), (['direct', 'VERB'], [0.0, 0.0, 1.0]), (['moodiness', 'NOUN'], [0.125, 0.875, 0.0]), (['not', 'ADV'], [0.0, 0.625, 0.375])]\n",
            "[(['pretentious', 'ADJ'], [0.125, 0.375, 0.5])]\n",
            "-1.125\n",
            "The word well is considered a stopword and the removed, the word pretentious has a negative score in the negated context, this because is probably considered a positive word by sentiwordnet.\n",
            "\n",
            "[(['boast', 'VERB'], [0.0, 0.0, 1.0]), (['dry', 'ADJ'], [0.0, 0.25, 0.75]), (['humor', 'NOUN'], [0.0, 0.0, 1.0]), (['jarring', 'ADJ'], [0.0, 0.625, 0.375]), (['shock', 'NOUN'], [0.0, 0.75, 0.25]), (['plus', 'CCONJ'], [0, 0, 0]), (['moment', 'NOUN'], [0.0, 0.0, 1.0]), (['breathtake', 'VERB'], [0, 0, 0]), (['mystery', 'NOUN'], [0.25, 0.0, 0.75])]\n",
            "[]\n",
            "-1.375\n",
            "Words like dry and shocks are considered negative, so this influence the overall polarity of the sentence.\n",
            "\n",
            "Class 0 example:\n",
            "[(['crime', 'NOUN'], [0.0, 0.0, 1.0]), (['obviously', 'ADV'], [0.5, 0.0, 0.5]), (['know', 'VERB'], [0.0, 0.0, 1.0]), (['crime', 'NOUN'], [0.0, 0.0, 1.0])]\n",
            "[]\n",
            "0.5\n",
            "Obviously is considered a positive word, the complex semantic of the sentence is not manageble by the sentiwordnet algorithm.\n",
            "\n",
            "[(['precious', 'ADJ'], [0.625, 0.25, 0.125]), (['new', 'ADJ'], [0.375, 0.0, 0.625]), (['star', 'PROPN'], [0, 0, 0]), (['wars', 'PROPN'], [0, 0, 0]), (['lumbering', 'NOUN'], [0.0, 0.0, 1.0]), (['wheezy', 'ADJ'], [0.0, 0.0, 1.0]), (['drag', 'NOUN'], [0.0, 0.0, 1.0])]\n",
            "[]\n",
            "0.75\n",
            "Only the words precious and new gets a score. A positive one. This influence the overall polarity.\n",
            "\n",
            "[(['philosophically', 'ADV'], [0.25, 0.0, 0.75]), (['intellectually', 'ADV'], [0.25, 0.0, 0.75]), (['logistically', 'ADV'], [0, 0, 0]), (['mess', 'NOUN'], [0.0, 0.125, 0.875])]\n",
            "[]\n",
            "0.375\n",
            "Philosophically and intellectually gets a positive score. The word mess has not a sufficient negative score to influence the overall sentiment of the sentence.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However we can try to use the full dataset to derive a score and then train a ML model to convert a score into a class.<br>\n",
        "I do not expect big improvement since the score itself suffer of severe biases, however, I'll make a try."
      ],
      "metadata": {
        "id": "wdN1DupWuwsr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a ML model to convert scores into classes"
      ],
      "metadata": {
        "id": "bA_ififX5B36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all the computation of the sentiment score for each word of each sentence is performed, this first step take a bit of time, about 15 minutes."
      ],
      "metadata": {
        "id": "C38RhX-lZqGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores_array = train['Phrase'].apply(get_sentiment_array, neg_factor=1, debug=False)\n"
      ],
      "metadata": {
        "id": "YgzHDMBQ4J59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "scores = scores_array.apply(get_sentiment_score)\n",
        "sentiment = train['Sentiment']\n",
        "phrase = train['Phrase']\n",
        "list_data = list(zip(phrase, sentiment))\n",
        "train_set = pd.DataFrame(list_data,columns = ['Phrase','Sentiment'])\n",
        "\n",
        "models = []\n",
        "models.append(('Support Vector Machine',LinearSVC(max_iter=9000)))\n",
        "models.append(('Decision Tree',DecisionTreeClassifier()))\n",
        "models.append(('Logistic Regression',LogisticRegression(max_iter=9000)))\n",
        "\n",
        "# compare models with 3-fold cross-validation\n",
        "kf = model_selection.StratifiedKFold(n_splits=3,shuffle=True, random_state = 1)\n",
        "\n",
        "scores = scores.values.reshape(-1,1)\n",
        "\n",
        "for name, model in models:\n",
        "    cv_scores = model_selection.cross_val_score(model, scores, train_set['Sentiment'], cv=kf)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_scores.mean(), cv_scores.std())\n",
        "    print(msg)"
      ],
      "metadata": {
        "id": "9V4ABHODCPiy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60bd1484-a145-484f-cf0f-28a7868fca38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine: 0.512566 (0.000220)\n",
            "Decision Tree: 0.530495 (0.000941)\n",
            "Logistic Regression: 0.517826 (0.000199)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tests made using a 3-fold cross validation ends up with the following results: <br>\n",
        "Support Vector Machine: 0.512566 (0.000220)<br>\n",
        "Decision Tree: 0.530495 (0.000941)<br>\n",
        "Logistic Regression: 0.517826 (0.000199)<br>\n",
        "These results are surely better than the one obtained using my algorithm, however are not better than the ones obtained in the previous section, rather, are drastically lower. <br>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "A way to improve these results can be trying to use the array with three values of polarities instead of using my derived score.<br>\n",
        "Probably my single score loose some hidden pattern in the scoring of words that can end up to be exploited by the models in order to improve their accuracy."
      ],
      "metadata": {
        "id": "n95pvatqKI-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = scores_array.apply(get_sentiment_triplet)\n",
        "scores =  pd.DataFrame.from_records(scores).to_numpy()"
      ],
      "metadata": {
        "id": "RFWJ6_lMLM5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = []\n",
        "models.append(('Decision Tree',DecisionTreeClassifier()))\n",
        "models.append(('Logistic Regression',LogisticRegression(max_iter=9000)))\n",
        "models.append(('Bayes',MultinomialNB()))\n",
        "#SVC removed since it does not converge in this context, i put Bayes in it's place since now we dealk with only positive value and then is usable.\n",
        "for name, model in models:\n",
        "    cv_scores = model_selection.cross_val_score(model, scores, train_set['Sentiment'], cv=kf)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_scores.mean(), cv_scores.std())\n",
        "    print(msg)"
      ],
      "metadata": {
        "id": "XTzvqNeMjKPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa8d8691-d3ce-4aa4-e8e3-ad66481d3aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree: 0.536909 (0.001286)\n",
            "Logistic Regression: 0.530142 (0.001608)\n",
            "Bayes: 0.510111 (0.000125)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tests made using a 3-fold cross validation ends up with the following results:<br>\n",
        "Decision Tree: 0.536909 (0.001286)<br>\n",
        "Logistic Regression: 0.530142 (0.001608)<br>\n",
        "Bayes: 0.510111 (0.000125)<br>\n",
        "\n",
        "These results are queite similar to the previous, so these kind of machine learnign model cannot exploit the sentiment array properly in order to obtain information about the right class.<br>\n",
        "This, as said before, is probably imputable to the inherent complexity of the task."
      ],
      "metadata": {
        "id": "Kzug2Rl2j4b2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a Neural Network model to convert scores into classes"
      ],
      "metadata": {
        "id": "thNv_-cJklMM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before give up and go on with other technique I want to make a last experiment using the sentiwordnet feature.<br>\n",
        "Using the previuos arrays of three component [pos,neg,obj] derived for each review, i want try to train a neural network and see if a more complex model is capable of extract some hidden rule that allow to correct classify the review starting from the polarity array."
      ],
      "metadata": {
        "id": "MaUDEMpOkqJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buildmodel():\n",
        "    model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(3,1)),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),#regularization\n",
        "    keras.layers.Dense(16, activation='relu'),  \n",
        "    keras.layers.Dense(5, activation='softmax')\n",
        "    ])\n",
        "    model.summary()\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return(model)"
      ],
      "metadata": {
        "id": "24aOI9rioCpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(scores,sentiment, test_size = 0.3, random_state = 60,shuffle=True, stratify=sentiment)\n",
        "model = buildmodel()\n",
        "# model fitting\n",
        "model.fit(X_train, Y_train,  validation_data=(X_test, Y_test)) \n",
        "\n"
      ],
      "metadata": {
        "id": "S_HtIj-O404T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0df37330-4a1e-46ed-f2fe-35a2c51cad14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 3)                 0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                256       \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 16)                1040      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 5)                 85        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,381\n",
            "Trainable params: 1,381\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "3414/3414 [==============================] - 13s 3ms/step - loss: 1.1847 - accuracy: 0.5245 - val_loss: 1.1456 - val_accuracy: 0.5368\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4508f88c10>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = buildmodel()\n",
        "final_model.fit(scores, train_set['Sentiment'])\n",
        "\n",
        "processed_test = scores_array = test['Phrase'].apply(get_sentiment_array, neg_factor=1, debug=False)\n",
        "processed_test = processed_test.apply(get_sentiment_triplet)\n",
        "processed_test =  pd.DataFrame.from_records(processed_test).to_numpy()\n",
        "\n",
        "test_id = test['PhraseId']\n",
        "\n",
        "y_prdict = final_model.predict(processed_test)\n",
        "y = np.argmax(y_prdict, axis=1)\n",
        "submission = pd.DataFrame(list(zip(test_id, y)),\n",
        "               columns =['PhraseId', 'Sentiment'])\n",
        "submission.head(20)\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/NLP Sentiment Challenge/submission_test_swnn.csv', index=False)\n",
        "#kaggle score: 0.54193  \\"
      ],
      "metadata": {
        "id": "5ApVIxzuNAdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e27ade8-12bc-4ee1-8880-90469aa4e1e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 3)                 0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                256       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 16)                1040      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 5)                 85        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,381\n",
            "Trainable params: 1,381\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "4877/4877 [==============================] - 12s 2ms/step - loss: 1.1790 - accuracy: 0.5256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training with 10 epoch and validation set ends up with the following results:<br>\n",
        "Multi Layer Perceptron: 0.5245 (may vary on several runs)<br>\n",
        "Kaggle score: 0.54193\n",
        "\n",
        "---\n",
        "\n",
        "This is the best between every tests made using the polarity array.<br>\n",
        "However the accuracy is really far for the one reached using the previous approach.<br>\n",
        "Probably is still possible to increase this results crafting a more sophisticated algorithm that is capable of catch sentiment inversion also when words like \"but\", \"however\", \"instead\" are used, or when the negation are used as reinforcement (\"I never been so happy\") or as a smoothing (\"It's not so bad) where there is not a real inversion, but just a decrease of the original sentiment.<br>\n",
        "All this nuances are not managed by my simple algorithm and to be honest, the natural language is so full of trick that I think is really difficult to use this kind of method in a context like this one.<br>\n",
        "We need more powerful method that are capable of extract the semantic of words without too much human intervention on the kind of words and pattern that are useful for the task.<br>\n",
        "These model are the LSTM Neural Networks and the Tranformers."
      ],
      "metadata": {
        "id": "aQ9SFqgeJ3W7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Third attempt: LSTM and GRU\n",
        "Kaggle score for LSTM: 0.62511<br>\n",
        "Kaggle score for GRU: 0.62256"
      ],
      "metadata": {
        "id": "jrho5x-pzm13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM (long short term memory) and GRU (gated recurrent unit) are two kind of neural network that can be viewed as an evolution of Recurrent Neural Network, overcoming their limitation about the vanishing gradient problem which doesn't allow to keep track of a sufficient amount of information.<br>\n",
        "These two model are really good in dealing with sequence of data like texts or sounds, so will be used to try to resolve our sentiment analysis problem."
      ],
      "metadata": {
        "id": "RBu_NSu6zt7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reloading data... Just to be sure\n",
        "train = pd.read_table('/content/drive/MyDrive/NLP Sentiment Challenge/train.tsv')\n",
        "test = pd.read_table('/content/drive/MyDrive/NLP Sentiment Challenge/test.tsv')"
      ],
      "metadata": {
        "id": "ZqC0rAC9_STb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing "
      ],
      "metadata": {
        "id": "IYiBFXoO3stw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to feed the neural network we need, as in the previuos experiments, to preprocess the data in order to make more simple to deal with the text.<br>\n",
        "I will apply the a different sequence of preprocessing step since LSTM are more sensible to the order of words, so i will not remove stopwords."
      ],
      "metadata": {
        "id": "dv1FikaZ3vT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_train = copy(train)\n",
        "processed_train['Phrase'] = processed_train['Phrase'].apply(preprocessDataset, split = True, stopword = False, normalization = 'stem')\n",
        "phrase = processed_train['Phrase']\n",
        "sentiment = processed_train['Sentiment']\n"
      ],
      "metadata": {
        "id": "zjBK-ilE4nsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now every words need to be transformed into a numerical value in order to be manageable by models.<br>\n",
        "The most simple way to deal with this is the one hot encoding, i will use the one offered by keras."
      ],
      "metadata": {
        "id": "bmeXGJug6OdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vocabulary_stats(phrases):\n",
        "  unique_words = set()\n",
        "  len_max = 0\n",
        "\n",
        "  for sent in phrases:\n",
        "      \n",
        "      unique_words.update(sent)\n",
        "      \n",
        "      if(len_max<len(sent)):\n",
        "          len_max = len(sent)\n",
        "          \n",
        "  #length of the list of unique_words gives the no of unique words\n",
        "  tot_word = len(list(unique_words))\n",
        "  #print(tot_word)\n",
        "  #print(len_max)\n",
        "  #print(unique_words)\n",
        "  return(tot_word,len_max)\n",
        "\n",
        "voc_stats=get_vocabulary_stats(phrase)\n",
        "encoded_phrases = [one_hot(' '.join(d), voc_stats[0], lower = False) for d in phrase]\n",
        "encoded_phrases = keras.preprocessing.sequence.pad_sequences(encoded_phrases, maxlen=voc_stats[1])\n",
        "\n",
        "print(encoded_phrases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3JRkCGUoFH7",
        "outputId": "8875f8b5-02c8-41e1-c52b-c422164ccccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0 ... 3209 1941  147]\n",
            " [   0    0    0 ... 4386 2644 7913]\n",
            " [   0    0    0 ...    0 1941 6872]\n",
            " ...\n",
            " [   0    0    0 ...    0 7868 7318]\n",
            " [   0    0    0 ...    0    0 7868]\n",
            " [   0    0    0 ...    0    0 7318]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_test = copy(test)\n",
        "processed_test['Phrase'] = processed_test['Phrase'].apply(preprocessDataset, split = True, stopword = False, normalization = 'stem')\n",
        "test_phrase = processed_test['Phrase']\n",
        "test_voc_stats=get_vocabulary_stats(test_phrase)\n",
        "encoded_test_phrases = [one_hot(' '.join(d), voc_stats[0], lower = False) for d in test_phrase]\n",
        "encoded_test_phrases = keras.preprocessing.sequence.pad_sequences(encoded_test_phrases, maxlen=voc_stats[1])\n",
        "test_id = test['PhraseId']"
      ],
      "metadata": {
        "id": "S__FxIjGDpt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSTM"
      ],
      "metadata": {
        "id": "RW_MK-eY_mkS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After have represented every word with a number is necessary, in order to make data suitable for lstm, to transform every number into a vector. This operation is called *embedding* and is used to put every word into a complex geometric space in which is possible make comparison; we can see it as a sort of mathematical abstraction of the human concept of \"semantic\".<br> This step is performed by the first layer of the following model:"
      ],
      "metadata": {
        "id": "jKXFmQUS5P3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lstm_model():\n",
        "  lstm_model = Sequential()\n",
        "  inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "  # Embed each integer in a 32-dimensional vector\n",
        "  lstm_model.add(inputs)\n",
        "  lstm_model.add(Embedding(voc_stats[0], 32)) \n",
        "  # Add 1 bidirectional LSTMs\n",
        "  #bidirectional means that is trained viewing input in both direction, from the \"past\" and from the \"future\", this allows to reach more accuracy\n",
        "  lstm_model.add(Bidirectional(LSTM(128,dropout = 0.5)))\n",
        "  # Add a classifier\n",
        "  lstm_model.add(Dense(5, activation=\"softmax\"))\n",
        "  lstm_model.summary()\n",
        "  lstm_model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "  return lstm_model"
      ],
      "metadata": {
        "id": "-bjVysmKtvas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = get_lstm_model()\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(encoded_phrases,sentiment, test_size = 0.3, random_state = 60,shuffle=True, stratify=sentiment)\n",
        "# model fitting\n",
        "lstm_model.fit(X_train, Y_train,  validation_data=(X_test, Y_test),batch_size = 32, epochs=10) #number of epoch choose making some previous experiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaNFyfdPvyuq",
        "outputId": "0fa6fadd-781e-4fca-bc53-05022163590f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, None, 32)          339616    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 256)              164864    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 505,765\n",
            "Trainable params: 505,765\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "3414/3414 [==============================] - 38s 10ms/step - loss: 1.0593 - accuracy: 0.5737 - val_loss: 0.9199 - val_accuracy: 0.6219\n",
            "Epoch 2/10\n",
            "3414/3414 [==============================] - 33s 10ms/step - loss: 0.9074 - accuracy: 0.6261 - val_loss: 0.8898 - val_accuracy: 0.6325\n",
            "Epoch 3/10\n",
            "3414/3414 [==============================] - 34s 10ms/step - loss: 0.8642 - accuracy: 0.6437 - val_loss: 0.8719 - val_accuracy: 0.6403\n",
            "Epoch 4/10\n",
            "3414/3414 [==============================] - 33s 10ms/step - loss: 0.8382 - accuracy: 0.6549 - val_loss: 0.8584 - val_accuracy: 0.6467\n",
            "Epoch 5/10\n",
            "3414/3414 [==============================] - 35s 10ms/step - loss: 0.8210 - accuracy: 0.6627 - val_loss: 0.8576 - val_accuracy: 0.6472\n",
            "Epoch 6/10\n",
            "3414/3414 [==============================] - 33s 10ms/step - loss: 0.8038 - accuracy: 0.6698 - val_loss: 0.8486 - val_accuracy: 0.6515\n",
            "Epoch 7/10\n",
            "3414/3414 [==============================] - 33s 10ms/step - loss: 0.7916 - accuracy: 0.6752 - val_loss: 0.8424 - val_accuracy: 0.6539\n",
            "Epoch 8/10\n",
            "3414/3414 [==============================] - 32s 9ms/step - loss: 0.7792 - accuracy: 0.6802 - val_loss: 0.8374 - val_accuracy: 0.6548\n",
            "Epoch 9/10\n",
            "3414/3414 [==============================] - 33s 10ms/step - loss: 0.7705 - accuracy: 0.6842 - val_loss: 0.8393 - val_accuracy: 0.6548\n",
            "Epoch 10/10\n",
            "3414/3414 [==============================] - 32s 10ms/step - loss: 0.7615 - accuracy: 0.6874 - val_loss: 0.8363 - val_accuracy: 0.6563\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45002a1510>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ends up with an accuracy of more than 0.65 on the validation set.<br> This is a big improvement from the previous experiment and it was possible using a quite more simple model than others seen in other experiments about lstm (less layers, less embedding dimesion).<br>\n",
        "Let's try it on the real test set."
      ],
      "metadata": {
        "id": "-NSWPcrmRoHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = get_lstm_model()\n",
        "lstm_model.fit(encoded_phrases, sentiment ,batch_size = 32, epochs=10) #train on the full training set\n",
        "y_prdict = lstm_model.predict(encoded_test_phrases)\n",
        "y = np.argmax(y_prdict, axis=1)\n",
        "submission = pd.DataFrame(list(zip(test_id, y)),\n",
        "               columns =['PhraseId', 'Sentiment'])\n",
        "submission.head(20)\n",
        " \n",
        "submission.to_csv('/content/drive/MyDrive/NLP Sentiment Challenge/submission_lstm.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCfDvGQ9Etd8",
        "outputId": "8a4ff4b8-982f-4855-8517-3d6ae824a932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, None, 32)          339616    \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 256)              164864    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 505,765\n",
            "Trainable params: 505,765\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4877/4877 [==============================] - 43s 8ms/step - loss: 1.0195 - accuracy: 0.5868\n",
            "Epoch 2/10\n",
            "4877/4877 [==============================] - 39s 8ms/step - loss: 0.8919 - accuracy: 0.6326\n",
            "Epoch 3/10\n",
            "4877/4877 [==============================] - 39s 8ms/step - loss: 0.8570 - accuracy: 0.6466\n",
            "Epoch 4/10\n",
            "4877/4877 [==============================] - 40s 8ms/step - loss: 0.8327 - accuracy: 0.6563\n",
            "Epoch 5/10\n",
            "4877/4877 [==============================] - 41s 8ms/step - loss: 0.8153 - accuracy: 0.6643\n",
            "Epoch 6/10\n",
            "4877/4877 [==============================] - 40s 8ms/step - loss: 0.8023 - accuracy: 0.6689\n",
            "Epoch 7/10\n",
            "4877/4877 [==============================] - 40s 8ms/step - loss: 0.7907 - accuracy: 0.6753\n",
            "Epoch 8/10\n",
            "4877/4877 [==============================] - 41s 8ms/step - loss: 0.7815 - accuracy: 0.6778\n",
            "Epoch 9/10\n",
            "4877/4877 [==============================] - 39s 8ms/step - loss: 0.7726 - accuracy: 0.6817\n",
            "Epoch 10/10\n",
            "4877/4877 [==============================] - 39s 8ms/step - loss: 0.7666 - accuracy: 0.6842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We obtain a score of 0.62511 that is the best one so far.<br>"
      ],
      "metadata": {
        "id": "7KJ_IOhnSorX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GRU"
      ],
      "metadata": {
        "id": "T7A9VcS7T44a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gru_model():\n",
        "  gru_model = Sequential()\n",
        "  inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "  # Embedded each integer in a 32-dimensional vector\n",
        "  gru_model.add(inputs)\n",
        "  gru_model.add(Embedding(voc_stats[0], 32))\n",
        "  # Add 1 bidirectional GRU\n",
        "  gru_model.add(Bidirectional(GRU(128,dropout = 0.5, return_sequences=False)))\n",
        "  # Add a classifier\n",
        "  gru_model.add(Dense(5, activation=\"softmax\"))\n",
        "  gru_model.summary()\n",
        "  gru_model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "  return gru_model\n",
        "\n"
      ],
      "metadata": {
        "id": "hvQcCYOpUoQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model = get_gru_model()\n",
        "# model fitting\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(encoded_phrases,sentiment, test_size = 0.3, random_state = 60,shuffle=True, stratify=sentiment)\n",
        "gru_model.fit(X_train, Y_train,  validation_data=(X_test, Y_test),batch_size = 32, epochs=10) #number of epoch choose making some previous experiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DMzcKx3Wrgp",
        "outputId": "4973c5f1-c219-4cf4-e0c6-d79833e642f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, None, 32)          339616    \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 256)              124416    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 465,317\n",
            "Trainable params: 465,317\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "3414/3414 [==============================] - 33s 9ms/step - loss: 1.0405 - accuracy: 0.5781 - val_loss: 0.9204 - val_accuracy: 0.6184\n",
            "Epoch 2/10\n",
            "3414/3414 [==============================] - 31s 9ms/step - loss: 0.9039 - accuracy: 0.6289 - val_loss: 0.8822 - val_accuracy: 0.6377\n",
            "Epoch 3/10\n",
            "3414/3414 [==============================] - 30s 9ms/step - loss: 0.8638 - accuracy: 0.6450 - val_loss: 0.8674 - val_accuracy: 0.6440\n",
            "Epoch 4/10\n",
            "3414/3414 [==============================] - 31s 9ms/step - loss: 0.8403 - accuracy: 0.6557 - val_loss: 0.8655 - val_accuracy: 0.6442\n",
            "Epoch 5/10\n",
            "3414/3414 [==============================] - 31s 9ms/step - loss: 0.8216 - accuracy: 0.6621 - val_loss: 0.8585 - val_accuracy: 0.6459\n",
            "Epoch 6/10\n",
            "3414/3414 [==============================] - 30s 9ms/step - loss: 0.8057 - accuracy: 0.6692 - val_loss: 0.8535 - val_accuracy: 0.6511\n",
            "Epoch 7/10\n",
            "3414/3414 [==============================] - 31s 9ms/step - loss: 0.7936 - accuracy: 0.6728 - val_loss: 0.8503 - val_accuracy: 0.6528\n",
            "Epoch 8/10\n",
            "3414/3414 [==============================] - 30s 9ms/step - loss: 0.7805 - accuracy: 0.6815 - val_loss: 0.8514 - val_accuracy: 0.6519\n",
            "Epoch 9/10\n",
            "3414/3414 [==============================] - 30s 9ms/step - loss: 0.7655 - accuracy: 0.6856 - val_loss: 0.8448 - val_accuracy: 0.6535\n",
            "Epoch 10/10\n",
            "3414/3414 [==============================] - 30s 9ms/step - loss: 0.7515 - accuracy: 0.6915 - val_loss: 0.8460 - val_accuracy: 0.6527\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f452cedd310>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRU ends up with similar results than lstm, but GRU are inerenthly more simple as model so it probaly will ends up with a lower accuracy.\n",
        "Let's see how it behave on the test set."
      ],
      "metadata": {
        "id": "WKcu1g14Yn_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model = get_gru_model()\n",
        "gru_model.fit(encoded_phrases, sentiment ,batch_size = 32, epochs=10) #train on the full trainign set\n",
        "y_prdict = gru_model.predict(encoded_test_phrases)\n",
        "y = np.argmax(y_prdict, axis=1)\n",
        "submission = pd.DataFrame(list(zip(test_id, y)),\n",
        "               columns =['PhraseId', 'Sentiment'])\n",
        "submission.head(20)\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/NLP Sentiment Challenge/submission_gru.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kK1TA3URJJ8H",
        "outputId": "dcd5c7ac-dfc4-4072-94c9-7729e60af366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, None, 32)          339616    \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirectio  (None, 256)              124416    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 465,317\n",
            "Trainable params: 465,317\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4877/4877 [==============================] - 40s 7ms/step - loss: 1.0105 - accuracy: 0.5899\n",
            "Epoch 2/10\n",
            "4877/4877 [==============================] - 36s 7ms/step - loss: 0.8896 - accuracy: 0.6342\n",
            "Epoch 3/10\n",
            "4877/4877 [==============================] - 36s 7ms/step - loss: 0.8544 - accuracy: 0.6492\n",
            "Epoch 4/10\n",
            "4877/4877 [==============================] - 36s 7ms/step - loss: 0.8295 - accuracy: 0.6598\n",
            "Epoch 5/10\n",
            "4877/4877 [==============================] - 36s 7ms/step - loss: 0.8144 - accuracy: 0.6660\n",
            "Epoch 6/10\n",
            "4877/4877 [==============================] - 36s 7ms/step - loss: 0.7944 - accuracy: 0.6731\n",
            "Epoch 7/10\n",
            "4877/4877 [==============================] - 36s 7ms/step - loss: 0.7777 - accuracy: 0.6803\n",
            "Epoch 8/10\n",
            "4877/4877 [==============================] - 36s 7ms/step - loss: 0.7658 - accuracy: 0.6849\n",
            "Epoch 9/10\n",
            "4877/4877 [==============================] - 36s 7ms/step - loss: 0.7553 - accuracy: 0.6889\n",
            "Epoch 10/10\n",
            "4877/4877 [==============================] - 36s 7ms/step - loss: 0.7475 - accuracy: 0.6919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We obtain a score of 0.62256, slightly lower than the one obtained using the LSTM, as already said this is probably due to the simpler structure of this kind of cell."
      ],
      "metadata": {
        "id": "JvJb5qe7YsPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fourth Attempt: Transformers (transfer learning)\n",
        "Kaggle score: 0.67629"
      ],
      "metadata": {
        "id": "T24RRv-5fnUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the NLP world, and in general, in the current state of art of deep-learning models, one of the most effective way to manage complex problem is to use transfer learning technique.<br> Transfer learning consist in using some big pretrained model in order to exploit a level of complexity in the model that would be inaccessible for ordinary users or small companies.<br>\n",
        "This last attempt will use the transformer model Bert offered by Huggingface, a really big deep-learning model pretrained on a huge ammount of data that can help a lot in contexts like this."
      ],
      "metadata": {
        "id": "dwQUztXwAMul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\n",
        "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
      ],
      "metadata": {
        "id": "XlCCeCMyHx8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparing Dataset"
      ],
      "metadata": {
        "id": "uiJ5uuvBRUjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reloading data... Just to be sure\n",
        "train = pd.read_table('/content/drive/MyDrive/NLP Sentiment Challenge/train.tsv')\n",
        "test = pd.read_table('/content/drive/MyDrive/NLP Sentiment Challenge/test.tsv')\n",
        "\n",
        "train_data, validation_data = train_test_split(train, test_size = 0.3, random_state = 60,shuffle=True, stratify=train['Sentiment'])\n",
        "train_phrase = train_data['Phrase']\n",
        "train_sentiment = train_data['Sentiment']\n",
        "train_sentiment = tf.keras.utils.to_categorical(train_sentiment, num_classes=5)\n",
        "\n",
        "validation_phrase = validation_data['Phrase']\n",
        "validation_sentiment = validation_data['Sentiment']\n",
        "validation_sentiment = tf.keras.utils.to_categorical(validation_sentiment, num_classes=5)"
      ],
      "metadata": {
        "id": "m2jF0E3vOo9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset will be processed by the BERT tokenizer that transform sentences into a format readable and manageable by BERT model.<br>\n",
        "Something like this:"
      ],
      "metadata": {
        "id": "oXXo2_uvS4bb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![46561inputrepresent.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "XfGC-XInTPUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   **Token embeddings**: A [CLS] token is added to the input word tokens at the beginning of the first sentence and a [SEP] token is inserted at the end of each sentence.\n",
        "2.   **Segment embeddings**: A marker indicating Sentence A or Sentence B is added to each token. This allows the encoder to distinguish between sentences.\n",
        "3.   **Positional embeddings**: A positional embedding is added to each token to indicate its position in the sentence.\n",
        "---\n",
        "By means of this tokens BERT is capable of extract a model of the semantic of \n",
        "the text.<br>\n",
        "Since this text preprocessor is a TensorFlow model, It can be included in the model directly.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8SVKvnYjThe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Defining the BERT Model"
      ],
      "metadata": {
        "id": "DQC6qwUbRccy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  \n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dense(64, activation='relu')(net)\n",
        "  net = tf.keras.layers.Dropout(0.2)(net) #Regularization\n",
        "  net = tf.keras.layers.Dense(32, activation='relu')(net)\n",
        "  net = tf.keras.layers.Dropout(0.2)(net) #Regularization\n",
        "  net = tf.keras.layers.Dense(5, activation='softmax')(net)\n",
        "  return tf.keras.Model(text_input, net)"
      ],
      "metadata": {
        "id": "TY9IexOUJnIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training and Test"
      ],
      "metadata": {
        "id": "7f8zypVFRjhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model = build_classifier_model()\n",
        "classifier_model.compile(tf.keras.optimizers.Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "classifier_model.summary()\n",
        "train_history = classifier_model.fit(train_phrase, train_sentiment,  validation_data=(validation_phrase, validation_sentiment),epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQn39Z6EUfWN",
        "outputId": "bead5ec2-83a7-4ca3-868f-63bcefde8ab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " preprocessing (KerasLayer)     {'input_type_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'default': (None,   28763649    ['preprocessing[0][0]',          \n",
            "                                512),                             'preprocessing[0][1]',          \n",
            "                                 'encoder_outputs':               'preprocessing[0][2]']          \n",
            "                                 [(None, 128, 512),                                               \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 (None, 128, 512)],                                               \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 512)}                                                       \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 64)           32832       ['BERT_encoder[0][5]']           \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 64)           0           ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 32)           2080        ['dropout_14[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)           (None, 32)           0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 5)            165         ['dropout_15[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28,798,726\n",
            "Trainable params: 28,798,725\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "3414/3414 [==============================] - 682s 198ms/step - loss: 1.0911 - accuracy: 0.5616 - val_loss: 0.9045 - val_accuracy: 0.6385\n",
            "Epoch 2/5\n",
            "3414/3414 [==============================] - 660s 193ms/step - loss: 0.9453 - accuracy: 0.6191 - val_loss: 0.8477 - val_accuracy: 0.6528\n",
            "Epoch 3/5\n",
            "3414/3414 [==============================] - 657s 192ms/step - loss: 0.8755 - accuracy: 0.6486 - val_loss: 0.8185 - val_accuracy: 0.6590\n",
            "Epoch 4/5\n",
            "3414/3414 [==============================] - 655s 192ms/step - loss: 0.8236 - accuracy: 0.6697 - val_loss: 0.8074 - val_accuracy: 0.6646\n",
            "Epoch 5/5\n",
            "3414/3414 [==============================] - 655s 192ms/step - loss: 0.7818 - accuracy: 0.6882 - val_loss: 0.8006 - val_accuracy: 0.6663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ends up with an accuracy of 0.66 on the training set, let's see how behave on the full training set."
      ],
      "metadata": {
        "id": "OiURDnqTtWnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#commented in order to avoid run\n",
        "classifier_model = build_classifier_model()\n",
        "classifier_model.compile(tf.keras.optimizers.Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "sentiment = train['Sentiment']\n",
        "sentiment = tf.keras.utils.to_categorical(sentiment, num_classes=5)\n",
        "\n",
        "classifier_model.fit(train['Phrase'], sentiment ,batch_size = 32, epochs=5) #train on the full trainign set\n",
        "\n",
        "#Saving the model\n",
        "#classifier_model.save('/content/drive/MyDrive/NLP Sentiment Challenge/bert_model.h5')"
      ],
      "metadata": {
        "id": "mCk5AJpxK5tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#launch this if you want to load the saved model\n",
        "#classifier_model = keras.models.load_model(('/content/drive/MyDrive/NLP Sentiment Challenge/bert_model.h5'),custom_objects={'KerasLayer':hub.KerasLayer})"
      ],
      "metadata": {
        "id": "LpcNykRytiOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_id = test['PhraseId']\n",
        "y_prdict = classifier_model.predict(test['Phrase'])\n",
        "y = np.argmax(y_prdict, axis=1)\n",
        "submission = pd.DataFrame(list(zip(test_id, y)),\n",
        "               columns =['PhraseId', 'Sentiment'])\n",
        "submission.head(20)\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/NLP Sentiment Challenge/submission_bert.csv', index=False)"
      ],
      "metadata": {
        "id": "fY0Gf6AOLAkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ends up with a score of 0.67629 that is quite close to the most good result on Kaggle that is of 0.70.<br>\n",
        "Of course tuning hyperparamenter or trying other neural structure could bring to better result.<br>\n",
        "However this is a big improvement, we have to realize that is a quite unbalanced dataset with several classes and, in my humble opinion, also not so well labeled, so is quite difficult to obtain really good score."
      ],
      "metadata": {
        "id": "Dw5g5en6_w-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## That's all! Thank you for your... Attention :)"
      ],
      "metadata": {
        "id": "zUp4_AKu8GbF"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "odWrExVEyQFo",
        "UBWFf7c5dKoT",
        "neeIgBcEajWR",
        "d54pyJBlarOl",
        "qrbNsKo3a8Xk",
        "V86T14XTDsJt",
        "dU7FlhF7TvL3",
        "S7jKhVn2g34L",
        "mulXzTwJhBiq",
        "Bwtr9Z1AYAFg",
        "bA_ififX5B36",
        "thNv_-cJklMM",
        "jrho5x-pzm13",
        "IYiBFXoO3stw",
        "RW_MK-eY_mkS",
        "T7A9VcS7T44a",
        "T24RRv-5fnUq",
        "uiJ5uuvBRUjD",
        "DQC6qwUbRccy",
        "7f8zypVFRjhz"
      ],
      "name": "nlp_sentiment_challenge.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}